{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10f41c41-42cd-4cb0-88b1-616fe8f6ba8d",
   "metadata": {},
   "source": [
    "# Lexicon generation\n",
    "\n",
    "There are four pairs of traits for women and men proposed by Heilman (2012). Three example words for each group are listed in the following table.\n",
    "\n",
    "\n",
    "| Group-Masculine           |    Example Words                | Group-Feminine       |  Example Words       |\n",
    "| :--                       | :--:                            | :--                  | :--:                 |\n",
    "| achievement orientation   |competent, ambitious, achievement|concern for others    |kind, caring, considerate |\n",
    "| inclination to take charge|forceful, dominant, assertive    |affiliative tendencies| warm, collaborative, friendly|\n",
    "| autonomy                  |independent, decisive, autonomous| deference            |obedient, respectful, receptive|\n",
    "| rationality               |analytical, logical, objective   | emotional sensitivity| perceptive, understanding, intuitive|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17924a5-7c95-44d0-a0cd-5deaa7b800ca",
   "metadata": {},
   "source": [
    "I first experimented with `Empath` and `ChatGPT` for synonym extraction, however, the former can generate plenty of words describing an irrelevant topic, the latter often provides unstable responses. More importantly, both of them are impossible to have threshold for a more accurate measure of relevance.\n",
    "\n",
    "Therefore, extracting parts of speech and identifying synonyms through pre-trained embeddings are a better choice. The `word2vec-google-news-300` was considered in this notebook, which is a set of 300-dimensional vectors pre-trained on 100 billion words from Google news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d318ae-46ad-44ac-9aa4-32e821c3dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from gensim import downloader\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a3db913-921f-4321-9284-85e6e578c9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggl_model = downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3341903-003a-4fcb-8bd9-1b3c190c3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = ''\n",
    "TRAINED_MODEL_NAME = '4th_400_hst'\n",
    "FILE_NAMES = ['h1-100', 's1-100', 't1-100', 'h101-200','s101-200', 't101-200',\\\n",
    "              'h201-300', 's201-300', 't201-300', 'h301-400', 's301-400', 't301-400']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad1f8a-f8f2-4664-9440-8b3bbd351ec6",
   "metadata": {},
   "source": [
    "### Extract nouns and adjectives from the training set\n",
    "The first step is to keep all nouns and adjectives with a meaningful length (no smaller than 4).\n",
    "I also create a list of irrelevant words for an improved filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47b903e-5a9e-4df4-892d-3a5ca8fa8caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for f_name in FILE_NAMES:\n",
    "    with open(PATH + f_name +'.txt') as f:\n",
    "        file = f.read().replace('\\n','').split('.')\n",
    "        data += file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e6a9e8e-bd79-4e3a-97ba-0dc0e16ed271",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = set()\n",
    "nnn = set()\n",
    "for sentence in data:\n",
    "    tagged = pos_tag(word_tokenize(sentence))\n",
    "    n = set(word for word,tag in tagged if tag == \"NN\")\n",
    "    a = set(word for word,tag in tagged if tag[0] == \"J\")\n",
    "    nnn = nnn | n\n",
    "    adj = adj | a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bd67673-7bcc-4c8d-84fe-2f48af66f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant = set(['very','thing','something','anything','everything','nothing','final','whole','little',\\\n",
    "                 'easy','ruthless','cold','disrespectful','type','mindset','sort','insight','swift','rude',\\\n",
    "                 'demeanor','dramatic','cool','functional','accurate','simple','understood','learn','seamless',\\\n",
    "                 'particular','great','real','explanation','directness','imagine','wonderful','clever',\\\n",
    "                 'uncaring','truly','gentleman','quiet','calm','honorable','honest','candid','intrigued',\\\n",
    "                 'dismissive','satisfied','surprised','optimistic','apprehensive','attractive','hesitant', \\\n",
    "                 'impressed', 'uncomfortable', 'interested', 'skeptical', 'hopeful', 'unorthodox', 'attitude', \\\n",
    "                 'demeanor', 'tempting', 'compelling','achieve','experience','efficient','innovative','understand',\\\n",
    "                 'achieved','achieving','dominated','strive','cared','thought','knowledge', 'smart','brilliant',\\\n",
    "                 'volunteering'])\n",
    "adj = adj - irrelevant\n",
    "nnn = nnn - irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c72cd4c3-36da-41fe-8b4b-a375c7cabe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "la = list(adj)\n",
    "ln = list(nnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8261625b-9ab1-45e1-bb88-3a8f385ef4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "la = [i for i in la if len(i)>=4]\n",
    "ln = [i for i in ln if len(i)>=4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed3238-bcd5-4f59-9cc1-d10f79b5f199",
   "metadata": {},
   "source": [
    "### Define a threshold of synonym identification\n",
    "By computing paired similarity in google word2vec model for example words, it is clear that the majority of the example words are **semantically synonyms but not spatially similar**. The greatest value, 0.46, indicates a tentative threshold for synonyms of the cosine similarity measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf7c197c-4c8a-41f9-a787-f55b3317fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of base attributes\n",
    "h_achi = ['competent', 'ambitious', 'achievement']\n",
    "h_char = ['forceful', 'dominant', 'assertive']\n",
    "h_auto = ['independent', 'decisive', 'autonomous']\n",
    "h_ratn = ['analytical', 'logical', 'objective']\n",
    "s_cocn = ['kind', 'caring', 'considerate']\n",
    "s_affi = ['warm', 'collaborative', 'friendly']\n",
    "s_defe = ['obedient', 'respectful', 'receptive']\n",
    "s_emot = ['perceptive', 'understanding', 'intuitive']\n",
    "\n",
    "c_h_achi = ggl_model.similarity(h_achi[0], h_achi[1])\n",
    "c_h_char = ggl_model.similarity(h_char[0], h_char[1])\n",
    "c_h_auto = ggl_model.similarity(h_auto[0], h_auto[1])\n",
    "c_h_ratn = ggl_model.similarity(h_ratn[0], h_ratn[1])\n",
    "c_s_cocn = ggl_model.similarity(s_cocn[0], s_cocn[1])\n",
    "c_s_affi = ggl_model.similarity(s_affi[0], s_affi[1])\n",
    "c_s_defe = ggl_model.similarity(s_defe[0], s_defe[1])\n",
    "c_s_emot = ggl_model.similarity(s_emot[0], s_emot[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0432d6ee-b52a-456b-b34a-3de3b7ba443a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22667369,\n",
       " 0.29560408,\n",
       " 0.12045363,\n",
       " 0.18539125,\n",
       " 0.17777112,\n",
       " 0.102216855,\n",
       " 0.45882586,\n",
       " 0.26906115)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_h_achi, c_h_char, c_h_auto, c_h_ratn, c_s_cocn, c_s_affi, c_s_defe, c_s_emot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea00400-c88f-4c72-87fc-ebaede3fdd05",
   "metadata": {},
   "source": [
    "### Establish a rule of synonym identification\n",
    "Here are functions for synonym identification, measuring the similarity between a particular word and three example words.\n",
    "\n",
    "To balance the goal of identifying more traits and keeping them relevant to the example words at the same time: \n",
    "- Compute the paired similarities between a single word and three example words. \n",
    "- Use the greatest value among those three to describe the relevance of the word to this group.\n",
    "- Obtain similarity scores associated with eight groups.\n",
    "- Utilized 0.4 as the threshold of closeness - if a word is more relevant to one group and the similarity score is greater than 0.4, it will be selected for the lexicon of this group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51c63b7f-b5ef-401a-9d07-aa104f7856da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure the similarity between a single attribute and a list of base attributes\n",
    "\n",
    "def sim(attr, base_attr, model=ggl_model):\n",
    "    try:\n",
    "        s = -1 * np.ones(len(base_attr))\n",
    "        for i in range(len(base_attr)):\n",
    "            s[i] = model.similarity(attr, base_attr[i])\n",
    "        return max(s)     # can be changed\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "# assign a group for a single attribute from eight groups above\n",
    "\n",
    "def find_group(attr, threshold=0.4):\n",
    "    s = np.zeros(8)\n",
    "    l = np.array([h_achi, h_char, h_auto, h_ratn, s_cocn, s_affi, s_defe, s_emot], dtype=object)\n",
    "    l_name = np.array(['h_achi', 'h_char', 'h_auto', 'h_ratn', 's_cocn', 's_affi', 's_defe', 's_emot'])\n",
    "    for i, base_attr in enumerate(l):\n",
    "        s[i] = sim(attr, base_attr)\n",
    "    close = s > threshold\n",
    "    if close.sum() == 0:\n",
    "        return 0\n",
    "    elif close.sum() == 1:\n",
    "        return attr, l_name[close][0], s[close][0]\n",
    "    else:\n",
    "        return attr, l_name[np.argmax(s)], s.max()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce503f07-99ae-43d4-b5d5-62b7a31a3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_name = ['h_achi', 'h_char', 'h_auto', 'h_ratn', 's_cocn', 's_affi', 's_defe', 's_emot']\n",
    "\n",
    "tagged_attr = []\n",
    "tagged_grup = []\n",
    "tagged_siml = []\n",
    "attr_dict = {}\n",
    "\n",
    "for i in la:\n",
    "    gr = find_group(i, 0.4)\n",
    "    if gr != 0:\n",
    "        tagged_attr.append(gr[0])\n",
    "        tagged_grup.append(gr[1])\n",
    "        tagged_siml.append(gr[2])\n",
    "        \n",
    "        attr_dict[gr[1]] = attr_dict.get(gr[1],[])\n",
    "        attr_dict[gr[1]].append(gr[0])\n",
    "\n",
    "for i in ln:\n",
    "    gr = find_group(i, 0.4)\n",
    "    if gr != 0:\n",
    "        tagged_attr.append(gr[0])\n",
    "        tagged_grup.append(gr[1])\n",
    "        tagged_siml.append(gr[2])\n",
    "        \n",
    "        attr_dict[gr[1]] = attr_dict.get(gr[1],[])\n",
    "        attr_dict[gr[1]].append(gr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e3755f0-7c00-4ce8-be74-c5243322939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_sim = {tagged_attr[i]:tagged_siml[i] for i in range(len(tagged_siml))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c044d720-5b84-43ca-b866-b046a07b4ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'s_defe': 22,\n",
       "         'h_char': 28,\n",
       "         'h_achi': 22,\n",
       "         's_cocn': 33,\n",
       "         'h_auto': 10,\n",
       "         's_affi': 16,\n",
       "         's_emot': 20,\n",
       "         'h_ratn': 12})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(tagged_grup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f7585c5-7680-4018-b2b1-b7b559fbd253",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(attr_dict, open(\"attr_dict.json\", 'w'))\n",
    "json.dump(attr_sim, open(\"attr_sim.json\", 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
